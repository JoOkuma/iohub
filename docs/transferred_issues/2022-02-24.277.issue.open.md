# [\#277 Issue](https://github.com/mehta-lab/recOrder/issues/277) `open`: Append data using WaverOrder writer

#### <img src="https://avatars.githubusercontent.com/u/11934632?u=d8b0230acf4d049c5dc29dbf88fc019d7f5ec451&v=4" width="50">[ieivanov](https://github.com/ieivanov) opened issue at [2022-02-24 21:16](https://github.com/mehta-lab/recOrder/issues/277):

It would be very useful if we can append data to an existing zarr store using the WaveOrder writer. So far, I am using the `zarr` library to do that, but there is extra overhead, especially in formatting the metadata.

It would be useful to:
- add extra positions to an existing zarr store
- append or rewrite data in an existing array (e.g. if the first round of recon was not useful)
- expand the dimensions of an existing array (e.g. add extra channels or time points)

@camFoltz I know that we can open an existing zarr array with the WaveOrder writer, but I still haven't found a way to do any of the above. I know adding this functionality will be a bit of work, for now, in this issue, could you outline steps/function we need to write to accomplish that?

#### <img src="https://avatars.githubusercontent.com/u/2934183?u=e638cee77e71afc6e0579e50c2712dfe8a707869&v=4" width="50">[mattersoflight](https://github.com/mattersoflight) commented at [2022-02-24 23:42](https://github.com/mehta-lab/recOrder/issues/277#issuecomment-1316182404):

That's a great idea! In addition to updating the zarr store, @camFoltz can you link to code that is related to ome-zarr metadata?

#### <img src="https://avatars.githubusercontent.com/u/56048121?u=a40aaf1f40d0e83c96685f0724cb06eaa6b52708&v=4" width="50">[camFoltz](https://github.com/camFoltz) commented at [2022-03-09 00:03](https://github.com/mehta-lab/recOrder/issues/277#issuecomment-1316182410):

That will be a very useful feature.  What will truly be needed here is to have a method that opens an existing zarr store from the main writer.  We will then need to add checks to make sure that it conforms to HCS metadata standards in order to use the methods that live within the sub-writers (open_position, create_row, create_col, etc.).  I believe these methods should also update the metadata automatically (i.e. when a row is added, that is added to the `plate` dictionary in the zarr attributes).  The structure of the metadata is found here:

Highest Level (root.attrs): https://github.com/mehta-lab/waveorder/blob/master/waveorder/io/writer_structures.py#L398

Lowest Level (Pos_{iii}.attrs):  https://github.com/mehta-lab/waveorder/blob/master/waveorder/io/writer_structures.py#L310



Here are some pointers in where some of the other relevant code can be found:

> • add extra positions to an existing zarr store

Creating Positions (individual Writer Level):
https://github.com/mehta-lab/waveorder/blob/master/waveorder/io/writer_structures.py#L183

What will need to be done here is a safe method implemented at the high-level [writer](https://github.com/mehta-lab/waveorder/blob/master/waveorder/io/writer.py#L6) which uses this create position function.  This create positions function adds appropriate row/column subgroups.

> • append or rewrite data in an existing array (e.g. if the first round of recon was not useful)

This can be implemented at the `WriterBase` level -- do not have any code that performs tasks like this.

> • expand the dimensions of an existing array (e.g. add extra channels or time points)

Same as above, this can be implemented at the WriterBase level to modify an array and check to make sure that the proper low-level metadata is updated.


Overall, one has to make sure that anytime the structure of the store is changed (rows added, columns added, additional channels or timepoints added to the array) we need to update the existing HCS metadata.

HCS Standards can be found [here](https://ngff.openmicroscopy.org/0.1/)

Tag me if you have any more questions.

#### <img src="https://avatars.githubusercontent.com/u/2934183?u=e638cee77e71afc6e0579e50c2712dfe8a707869&v=4" width="50">[mattersoflight](https://github.com/mattersoflight) commented at [2022-11-21 21:53](https://github.com/mehta-lab/recOrder/issues/277#issuecomment-1322699102):

In addition to the features mentioned by Ivan, the ability to write the data to an existing zarr store or a newly conceived [TIFF stack dataset](https://github.com/mehta-lab/recOrder/issues/276#issuecomment-1322557745) will allow us to leverage the job scheduler on our HPC cluster for faster analysis.


-------------------------------------------------------------------------------



[Export of Github issue for [mehta-lab/recOrder](https://github.com/mehta-lab/recOrder). Generated on 2022.11.25 at 09:43:26.]
